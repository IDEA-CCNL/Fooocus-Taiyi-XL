{
    "path_checkpoints": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/checkpoints",
    "path_loras": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/loras",
    "path_embeddings": "/cognitive_comp/wuxiaojun/pretrained/pytorch/taiyi-diffusion-xl-base-1.0-text_encoder_pretrained/tokenizer",
    "path_vae_approx": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/vae_approx",
    "path_upscale_models": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/upscale_models",
    "path_inpaint": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/inpaint",
    "path_controlnet": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/controlnet",
    "path_clip_vision": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/clip_vision",
    "path_fooocus_expansion": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/models/prompt_expansion/fooocus_expansion",
    "path_outputs": "/cognitive_comp/wuxiaojun/github/text2img/Fooocus-Taiyi-XL/outputs"
}